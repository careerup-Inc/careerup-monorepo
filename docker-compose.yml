services:
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: careerup
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5

  auth-core:
    build:
      context: ./services/auth-core
      dockerfile: Dockerfile
    ports:
      - "8081:8081" # Expose the port auth-core listens on
      - "9091:9091"
    depends_on:
      postgres:
        condition: service_healthy # Wait for postgres to be ready
    environment:
      # Pass necessary environment variables for Spring Boot app
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/${POSTGRES_DB:-careerup}
      SPRING_DATASOURCE_USERNAME: ${POSTGRES_USER:-careerup}
      SPRING_DATASOURCE_PASSWORD: ${POSTGRES_PASSWORD:-careerup}
      JWT_SECRET: ${JWT_SECRET} # Pass JWT secret
    env_file:
      - .env
    restart: unless-stopped

  api-gateway:
    build:
      context: ./services/api-gateway
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    depends_on:
      - auth-core # Depends on auth service
      - chat-gateway # Depends on chat service
    env_file:
      - .env
    restart: unless-stopped

  chat-gateway:
    build:
      context: ./services/chat-gateway
      dockerfile: Dockerfile
    ports:
      - "8082:8082"
    depends_on:
      - llm-gateway-py
    env_file:
      - .env # Load LLM_SERVICE_ADDR
    restart: unless-stopped

  llm-gateway-py:
    build:
      context: .
      dockerfile: services/llm-gateway-py/Dockerfile
    ports:
      - "50054:50054"  # gRPC port
      - "8091:8091"    # HTTP admin port
    environment:
      # Service configuration
      - SERVICE_NAME=llm-gateway-py
      - ENVIRONMENT=development
      - DEBUG=true
      - LOG_LEVEL=DEBUG
      
      # Server configuration
      - GRPC_PORT=50054
      - HTTP_PORT=8091
      - MAX_WORKERS=10
      
      # Admin API
      - ENABLE_ADMIN_API=true
      - ADMIN_API_KEY=admin-secret-key
      
      # External APIs (set these in .env or as environment variables)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - TAVILY_API_KEY=${TAVILY_API_KEY}
      
      # Pinecone configuration
      - PINECONE_ENVIRONMENT=${PINECONE_ENVIRONMENT:-us-east-1-aws}
      - PINECONE_INDEX=${PINECONE_INDEX:-university-scores}
      
      # Feature flags
      - WEB_SEARCH_ENABLED=true
    env_file:
      - .env
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import grpc; grpc.channel_ready_future(grpc.insecure_channel('localhost:50054')).result(timeout=10)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

volumes:
  postgres_data:
  redis_data:

networks:
  default:
  careerup-network:
    external: true 